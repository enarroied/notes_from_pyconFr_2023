{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3240ac-7eb6-4e0c-b1e3-72053da1bc9f",
   "metadata": {},
   "source": [
    "# Continuous performance Analysis for Python\n",
    "\n",
    "*Following the conference By Arthur Pastel*\n",
    "\n",
    "This Notebook contains some samples of code. They are used to illustrate My blog article that summarizes the conferences I attended at the (very great) Pycon Fr 2023, in Bordeaux, France.\n",
    "\n",
    "The code samples shown here were mostly provided in the conference and I rewrote them with little change, and of course, added commentaries.\n",
    "\n",
    "/!\\ This notebook does not cover the main part of Arthur's presentation, which is the presentation of [Codspeed](https://codspeed.io/), which is still in development and is not thought for a data analysis / notebook kind of use. Codspeed is thought to test performance of programs that will run in production servers. With this being said, the other elements that were presented during his speech can be used with a notebook (and they are currently available), so this is what we present here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03297961-2f66-4705-8df6-b5addf47844c",
   "metadata": {},
   "source": [
    "## Creating a Demo function (Toy Algorithm)\n",
    "\n",
    "We create a function that calculates the [Fibonacci sequence](https://en.wikipedia.org/wiki/Fibonacci_number) in a recursive manner. We will be doing our performance tests on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95eeb4a-c77a-48d0-be94-a9f71d8b07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n: int) -> int:\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n - 1) + fibonacci(n - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f0d54-2e12-46c2-93ed-30e8bbe5eb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fibonacci(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea851a6d-a9cb-4232-b5c4-b268fe7a6a9d",
   "metadata": {},
   "source": [
    "## The basic approach\n",
    "\n",
    "The easiest way to test for performance is to measure the execution time before and after.\n",
    "\n",
    "For that, we can use ```time.perf_counter```, which is a high resolution timer, as you can see below.\n",
    "\n",
    "*We also have ```time.time```, which uses the system clock, but is less precise, so always prefer the above function to measure performance of functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970a9ba6-ff71-4f45-8dfa-2b2b1cabaacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time : 161.0 µs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "fibonacci(10)\n",
    "end = time.perf_counter()\n",
    "\n",
    "elapsed_time = round((end - start) * 10**6, 3)\n",
    "print(f\"Elapsed time : {elapsed_time} µs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f4287-7934-4cf7-b8e1-8bb7a600d8ae",
   "metadata": {},
   "source": [
    "A (big) problem of this approach, is that it depends on hardware and another problem is that it depends on whatever is being executed by the system at the time. A quick fix for the latter is to use basic statistics: run the test many times and do a mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbfa993-5b78-4cc1-aa89-835fc21c4fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 38.44 µs\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "for sample in range(100):\n",
    "    start = time.perf_counter()\n",
    "    fibonacci(10)\n",
    "    end = time.perf_counter()\n",
    "    samples.append(end - start)\n",
    "\n",
    "mean_perf = sum(samples) / len(samples)\n",
    "mean_perf_micros = round(mean_perf * 10**6, 3)\n",
    "print(f\"Mean : {mean_perf_micros} µs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c272aa-11b1-4dee-9a12-e07820237aef",
   "metadata": {},
   "source": [
    "As you can see, the differnce can be very big. At the conference, Arthur's slides showed around 12 to 13 µs, about half the time. Maybe he has a faster computer than mine, or maybe jupyter lab affects code performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4222b5-3737-4e20-988f-07230c0ff515",
   "metadata": {},
   "source": [
    "## Using specific libraries\n",
    "\n",
    "[pytest-benchmark](https://anaconda.org/anaconda/pytest-benchmark) is a specific library that allows us tho run performance tests. it takes care of all the previously defined steps (it runs the function several times and applies a statistical approach), plus it does some other fixees to the python environment that could affect performance. You can also [check the offical documentation](https://pytest-benchmark.readthedocs.io/en/stable/).\n",
    "\n",
    "The ipytest library allows us to use pytest with jupyter notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058d81b8-ee5c-4f11-ad56-a6b220a3bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4e013b-6aa3-4d9e-b465-5b2d6de7e94f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m---------------------------------------------------------------------------------------- benchmark: 3 tests ----------------------------------------------------------------------------------------\u001b[0m\n",
      "Name (time in us)          Min                   Max                Mean              StdDev              Median                 IQR            Outliers  OPS (Kops/s)            Rounds  Iterations\n",
      "\u001b[33m----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "test_fibo_5         \u001b[32m\u001b[1m    2.4000 (1.0)    \u001b[0m\u001b[32m\u001b[1m  1,373.8000 (1.0)    \u001b[0m\u001b[32m\u001b[1m    2.9909 (1.0)    \u001b[0m\u001b[32m\u001b[1m    8.2103 (1.0)    \u001b[0m\u001b[32m\u001b[1m    2.5000 (1.0)    \u001b[0m\u001b[32m\u001b[1m    0.0000 (1.0)    \u001b[0m 136;20825\u001b[32m\u001b[1m      334.3497 (1.0)    \u001b[0m   70423           1\n",
      "test_fibo_10        \u001b[1m   26.0000 (10.83)  \u001b[0m\u001b[31m\u001b[1m  4,436.7000 (3.23)   \u001b[0m\u001b[1m   45.3220 (15.15)  \u001b[0m\u001b[1m   67.4687 (8.22)   \u001b[0m\u001b[1m   26.6000 (10.64)  \u001b[0m\u001b[1m   34.8000 (>1000.0)\u001b[0m   517;511\u001b[1m       22.0643 (0.07)   \u001b[0m   27933           1\n",
      "test_fibo_15        \u001b[31m\u001b[1m  289.5000 (120.63) \u001b[0m\u001b[1m  1,563.0000 (1.14)   \u001b[0m\u001b[31m\u001b[1m  391.1006 (130.76) \u001b[0m\u001b[31m\u001b[1m  170.5564 (20.77)  \u001b[0m\u001b[31m\u001b[1m  293.7000 (117.48) \u001b[0m\u001b[31m\u001b[1m  172.8250 (>1000.0)\u001b[0m    234;99\u001b[31m\u001b[1m        2.5569 (0.01)   \u001b[0m    1409           1\n",
      "\u001b[33m----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "Legend:\n",
      "  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.\n",
      "  OPS: Operations Per Second, computed as 1 / Mean\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "def test_fibo_5(benchmark):\n",
    "    @benchmark\n",
    "    def _():\n",
    "        fibonacci(5)\n",
    "\n",
    "\n",
    "def test_fibo_10(benchmark):\n",
    "    @benchmark\n",
    "    def _():\n",
    "        fibonacci(10)\n",
    "\n",
    "\n",
    "def test_fibo_15(benchmark):\n",
    "    @benchmark\n",
    "    def _():\n",
    "        fibonacci(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625565c2-6104-45ad-aa10-ccc85439f500",
   "metadata": {},
   "source": [
    "The advantage of using the ```@benchmark``` decorator is that you could add code that executes before the test without affecting the performance of it:\n",
    "\n",
    "```python\n",
    "def some_test(benchmark):\n",
    "    # add some code here\n",
    "    x = whatever\n",
    "    @benchmark\n",
    "    def _():\n",
    "        some_function(x)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
